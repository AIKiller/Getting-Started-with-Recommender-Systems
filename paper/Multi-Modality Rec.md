Multi-Modality Rec

1. Wei Y, Wang X, Nie L, et al. MMGCN: Multi-modal graph convolution network for personalized recommendation of micro-video[C]//Proceedings of the 27th ACM international conference on multimedia. 2019: 1437-1445.

2. Wei Y, Wang X, Nie L, et al. Graph-refined convolutional network for multimedia recommendation with implicit feedback[C]//Proceedings of the 28th ACM international conference on multimedia. 2020: 3541-3549.

3. Qifan Wang, Yinwei Wei, Jianhua Yin, Jianlong Wu, Xuemeng Song, and Liqiang Nie. 2021. DualGNN: Dual Graph Neural Network for Multimedia Recommendation. IEEE Transactions on Multimedia (2021).

4. Jinghao Zhang, Yanqiao Zhu, Qiang Liu, Shu Wu, Shuhui Wang, and Liang Wang. 2021. Mining Latent Structures for Multimedia Recommendation. In Proceedings of the 29th ACM International Conference on Multimedia. 3872–3880.

5. Zhou X, Zhou H, Liu Y, et al. Bootstrap latent representations for multi-modal recommendation[C]//Proceedings of the ACM Web Conference 2023. 2023: 845-854.（**ps:这个文章注意，他论文的效果复现不出来，但是确实很多文章会把他当做baseline**）

6.Bai H, Wu L, Hou M, et al. Multimodality Invariant Learning for Multimedia-Based New Item Recommendation[C]//Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2024: 677-686.

7. Borg Bruun S, Balog K, Maistro M. Dataset and Models for Item Recommendation Using Multi-Modal User Interactions[C]//Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval. 2024: 709-718.
